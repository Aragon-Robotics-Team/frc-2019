package frc.robot.vision;

import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.io.Serializable;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;
import java.util.HashMap;
import java.util.Comparator;
import org.opencv.core.*;
import org.opencv.core.Core.*;
import org.opencv.features2d.FeatureDetector;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.*;
import org.opencv.objdetect.*;
import edu.wpi.first.vision.VisionPipeline;

/**
 * Grip class.
 *
 * <p>
 * An OpenCV pipeline generated by GRIP.
 *
 * @author GRIP
 */

public class Grip implements VisionPipeline {

	// Outputs
	private Mat normalizeOutput = new Mat();
	private Mat hslThresholdOutput = new Mat();
	private Mat cvErodeOutput = new Mat();
	private Mat cvDilateOutput = new Mat();
	public Mat AugmentCamOutput = new Mat();
	private ArrayList<MatOfPoint> findContoursOutput = new ArrayList<MatOfPoint>();
	private ArrayList<MatOfPoint> filterContoursOutput = new ArrayList<MatOfPoint>();
	private RotatedRect[] rects;
	private ArrayList<VisionTarget> visionTargets = new ArrayList<VisionTarget>();



	static {
		System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
	}

	/**
	 * This is the primary method that runs the entire pipeline and updates the outputs.
	 */
	public void process(Mat source0) {
		// Step Normalize0:
		Mat normalizeInput = source0;
		int normalizeType = Core.NORM_MINMAX;
		double normalizeAlpha = 0.0;
		double normalizeBeta = 255;
		normalize(normalizeInput, normalizeType, normalizeAlpha, normalizeBeta, normalizeOutput);

		// Step HSL_Threshold0:
		Mat hslThresholdInput = normalizeOutput;
		double[] hslThresholdHue = {0.0, 41.77474402730375};
		double[] hslThresholdSaturation = {146.76258992805754, 255.0};
		double[] hslThresholdLuminance = {0.0, 255.0};
		hslThreshold(hslThresholdInput, hslThresholdHue, hslThresholdSaturation,
				hslThresholdLuminance, hslThresholdOutput);

		// Step CV_erode0:
		Mat cvErodeSrc = hslThresholdOutput;
		Mat cvErodeKernel = new Mat();
		Point cvErodeAnchor = new Point(-1, -1);
		double cvErodeIterations = 8.0;
		int cvErodeBordertype = Core.BORDER_CONSTANT;
		Scalar cvErodeBordervalue = new Scalar(-1);
		cvErode(cvErodeSrc, cvErodeKernel, cvErodeAnchor, cvErodeIterations, cvErodeBordertype,
				cvErodeBordervalue, cvErodeOutput);

		// Step CV_dilate0:
		Mat cvDilateSrc = cvErodeOutput;
		Mat cvDilateKernel = new Mat();
		Point cvDilateAnchor = new Point(-1, -1);
		double cvDilateIterations = 6.0;
		int cvDilateBordertype = Core.BORDER_CONSTANT;
		Scalar cvDilateBordervalue = new Scalar(-1);
		cvDilate(cvDilateSrc, cvDilateKernel, cvDilateAnchor, cvDilateIterations,
				cvDilateBordertype, cvDilateBordervalue, cvDilateOutput);

		// Step Find_Contours0:
		Mat findContoursInput = cvDilateOutput;
		boolean findContoursExternalOnly = false;
		findContours(findContoursInput, findContoursExternalOnly, findContoursOutput);

		// Step Filter_Contours0:
		ArrayList<MatOfPoint> filterContoursContours = findContoursOutput;
		double filterContoursMinArea = 0.0;
		double filterContoursMinPerimeter = 150.0;
		double filterContoursMinWidth = 0.0;
		double filterContoursMaxWidth = 10000.0;
		double filterContoursMinHeight = 0.0;
		double filterContoursMaxHeight = 1000.0;
		double[] filterContoursSolidity = {0, 100};
		double filterContoursMaxVertices = 1000000.0;
		double filterContoursMinVertices = 0.0;
		double filterContoursMinRatio = 0.0;
		double filterContoursMaxRatio = 1000.0;
		filterContours(filterContoursContours, filterContoursMinArea, filterContoursMinPerimeter,
				filterContoursMinWidth, filterContoursMaxWidth, filterContoursMinHeight,
				filterContoursMaxHeight, filterContoursSolidity, filterContoursMaxVertices,
				filterContoursMinVertices, filterContoursMinRatio, filterContoursMaxRatio,
				filterContoursOutput);

		// step Find_targets I guess?
		getVisionTargets();

		// step draw contours
		for (int i = 0; i < filterContoursOutput.size(); i++) {
			Imgproc.drawContours(AugmentCamOutput, filterContoursOutput, i,
					new Scalar(255, 255, 255), -1);
		}
		// step draw rectangles around visiontargets
		for (int i = 0; i < visionTargets.size(); i++) {
			Imgproc.rectangle(AugmentCamOutput, visionTargets.get(i).bounding.tl(),
					visionTargets.get(i).bounding.br(), new Scalar(120, 255, 120));
		}
	}

	/**
	 * This method is a generated getter for the output of a Normalize.
	 * 
	 * @return Mat output from Normalize.
	 */
	public Mat normalizeOutput() {
		return normalizeOutput;
	}

	/**
	 * This method is a generated getter for the output of a HSL_Threshold.
	 * 
	 * @return Mat output from HSL_Threshold.
	 */
	public Mat hslThresholdOutput() {
		return hslThresholdOutput;
	}

	/**
	 * This method is a generated getter for the output of a CV_erode.
	 * 
	 * @return Mat output from CV_erode.
	 */
	public Mat cvErodeOutput() {
		return cvErodeOutput;
	}

	/**
	 * This method is a generated getter for the output of a CV_dilate.
	 * 
	 * @return Mat output from CV_dilate.
	 */
	public Mat cvDilateOutput() {
		return cvDilateOutput;
	}

	/**
	 * This method is a generated getter for the output of a Find_Contours.
	 * 
	 * @return ArrayList<MatOfPoint> output from Find_Contours.
	 */
	public ArrayList<MatOfPoint> findContoursOutput() {
		return findContoursOutput;
	}

	/**
	 * This method is a generated getter for the output of a Filter_Contours.
	 * 
	 * @return ArrayList<MatOfPoint> output from Filter_Contours.
	 */
	public ArrayList<MatOfPoint> filterContoursOutput() {
		return filterContoursOutput;
	}


	/**
	 * Normalizes or remaps the values of pixels in an image.
	 * 
	 * @param input  The image on which to perform the Normalize.
	 * @param type   The type of normalization.
	 * @param a      The minimum value.
	 * @param b      The maximum value.
	 * @param output The image in which to store the output.
	 */
	private void normalize(Mat input, int type, double a, double b, Mat output) {
		Core.normalize(input, output, a, b, type);
	}

	/**
	 * Segment an image based on hue, saturation, and luminance ranges.
	 *
	 * @param input  The image on which to perform the HSL threshold.
	 * @param hue    The min and max hue
	 * @param sat    The min and max saturation
	 * @param lum    The min and max luminance
	 * @param output The image in which to store the output.
	 */
	private void hslThreshold(Mat input, double[] hue, double[] sat, double[] lum, Mat out) {
		Imgproc.cvtColor(input, out, Imgproc.COLOR_BGR2HLS);
		Core.inRange(out, new Scalar(hue[0], lum[0], sat[0]), new Scalar(hue[1], lum[1], sat[1]),
				out);
	}

	/**
	 * Expands area of lower value in an image.
	 * 
	 * @param src         the Image to erode.
	 * @param kernel      the kernel for erosion.
	 * @param anchor      the center of the kernel.
	 * @param iterations  the number of times to perform the erosion.
	 * @param borderType  pixel extrapolation method.
	 * @param borderValue value to be used for a constant border.
	 * @param dst         Output Image.
	 */
	private void cvErode(Mat src, Mat kernel, Point anchor, double iterations, int borderType,
			Scalar borderValue, Mat dst) {
		if (kernel == null) {
			kernel = new Mat();
		}
		if (anchor == null) {
			anchor = new Point(-1, -1);
		}
		if (borderValue == null) {
			borderValue = new Scalar(-1);
		}
		Imgproc.erode(src, dst, kernel, anchor, (int) iterations, borderType, borderValue);
	}

	/**
	 * Expands area of higher value in an image.
	 * 
	 * @param src         the Image to dilate.
	 * @param kernel      the kernel for dilation.
	 * @param anchor      the center of the kernel.
	 * @param iterations  the number of times to perform the dilation.
	 * @param borderType  pixel extrapolation method.
	 * @param borderValue value to be used for a constant border.
	 * @param dst         Output Image.
	 */
	private void cvDilate(Mat src, Mat kernel, Point anchor, double iterations, int borderType,
			Scalar borderValue, Mat dst) {
		if (kernel == null) {
			kernel = new Mat();
		}
		if (anchor == null) {
			anchor = new Point(-1, -1);
		}
		if (borderValue == null) {
			borderValue = new Scalar(-1);
		}
		Imgproc.dilate(src, dst, kernel, anchor, (int) iterations, borderType, borderValue);
	}

	/**
	 * Sets the values of pixels in a binary image to their distance to the nearest black pixel.
	 * 
	 * @param input    The image on which to perform the Distance Transform.
	 * @param type     The Transform.
	 * @param maskSize the size of the mask.
	 * @param output   The image in which to store the output.
	 */
	private void findContours(Mat input, boolean externalOnly, List<MatOfPoint> contours) {
		Mat hierarchy = new Mat();
		contours.clear();
		int mode;
		if (externalOnly) {
			mode = Imgproc.RETR_EXTERNAL;
		} else {
			mode = Imgproc.RETR_LIST;
		}
		int method = Imgproc.CHAIN_APPROX_SIMPLE;
		Imgproc.findContours(input, contours, hierarchy, mode, method);
	}


	/**
	 * Filters out contours that do not meet certain criteria.
	 * 
	 * @param inputContours  is the input list of contours
	 * @param output         is the the output list of contours
	 * @param minArea        is the minimum area of a contour that will be kept
	 * @param minPerimeter   is the minimum perimeter of a contour that will be kept
	 * @param minWidth       minimum width of a contour
	 * @param maxWidth       maximum width
	 * @param minHeight      minimum height
	 * @param maxHeight      maximimum height
	 * @param Solidity       the minimum and maximum solidity of a contour
	 * @param minVertexCount minimum vertex Count of the contours
	 * @param maxVertexCount maximum vertex Count
	 * @param minRatio       minimum ratio of width to height
	 * @param maxRatio       maximum ratio of width to height
	 */
	private void filterContours(List<MatOfPoint> inputContours, double minArea, double minPerimeter,
			double minWidth, double maxWidth, double minHeight, double maxHeight, double[] solidity,
			double maxVertexCount, double minVertexCount, double minRatio, double maxRatio,
			List<MatOfPoint> output) {
		final MatOfInt hull = new MatOfInt();
		output.clear();
		// operation
		for (int i = 0; i < inputContours.size(); i++) {
			final MatOfPoint contour = inputContours.get(i);
			final Rect bb = Imgproc.boundingRect(contour);
			if (bb.width < minWidth || bb.width > maxWidth)
				continue;
			if (bb.height < minHeight || bb.height > maxHeight)
				continue;
			final double area = Imgproc.contourArea(contour);
			if (area < minArea)
				continue;
			if (Imgproc.arcLength(new MatOfPoint2f(contour.toArray()), true) < minPerimeter)
				continue;
			Imgproc.convexHull(contour, hull);
			MatOfPoint mopHull = new MatOfPoint();
			mopHull.create((int) hull.size().height, 1, CvType.CV_32SC2);
			for (int j = 0; j < hull.size().height; j++) {
				int index = (int) hull.get(j, 0)[0];
				double[] point = new double[] {contour.get(index, 0)[0], contour.get(index, 0)[1]};
				mopHull.put(j, 0, point);
			}
			final double solid = 100 * area / Imgproc.contourArea(mopHull);
			if (solid < solidity[0] || solid > solidity[1])
				continue;
			if (contour.rows() < minVertexCount || contour.rows() > maxVertexCount)
				continue;
			final double ratio = bb.width / (double) bb.height;
			if (ratio < minRatio || ratio > maxRatio)
				continue;
			output.add(contour);
		}
	}


	class VisionTarget implements Serializable {
		public double x;
		public double y;
		public Rect bounding;

		public VisionTarget(RotatedRect r1, RotatedRect r2) {
			// shit.. well:
			// r1 is implied to be the left rectangle
			// r2 is the right rectangle
			this.x = (r1.center.x + r2.center.x) / 2;
			this.y = (r1.center.y + r2.center.y) / 2;
			this.bounding = new Rect(r1.boundingRect().tl(), r2.boundingRect().br());
		}
	}

	public void getVisionTargets() {
		getMinAreaRects(); // fills rects array using contours

		sortRectsByX(); // in-place. This is to identify pairs. not the perfect solution
		for (int i = 0; i < rects.length - 1; i++) {
			if (isTarget(rects[i], rects[i + 1])) {
				visionTargets.add(new VisionTarget(rects[i], rects[i + 1]));
			}
		}



	}

	public boolean isTarget(RotatedRect rect1, RotatedRect rect2) {
		double angleDiff = Math.abs(correct_angle(rect1) - correct_angle(rect2));
		if (angleDiff < 110 && angleDiff > 70
				&& Math.abs(
						rect1.center.x - rect2.center.x) < (rect1.size.height + rect2.size.height)
				&& Math.abs(
						rect1.center.y - rect2.center.y) < (rect1.size.height + rect2.size.height)
								/ 2)
			return true;
		else
			return false;
	}

	public void getMinAreaRects() {
		rects = new RotatedRect[filterContoursOutput.size()];
		for (int i = 0; i < filterContoursOutput.size(); i++) {
			rects[i] = Imgproc.minAreaRect(new MatOfPoint2f(filterContoursOutput.get(i).toArray()));
		}
	}

	class RectComparator implements Comparator<RotatedRect> {
		public int compare(RotatedRect a, RotatedRect b) {
			return (int) (a.center.x - b.center.x);
		}
	}

	public void sortRectsByX() {
		// assuming this is smallest to largest for now, check RectComparator to fix
		Arrays.sort(rects, new RectComparator());
	}

	public double correct_angle(RotatedRect rect) {
		// don't touch... voodoo math inside
		double angle;
		if (rect.size.width < rect.size.height) {
			angle = -1 * (rect.angle - 90);
		} else {
			angle = rect.angle;
		}

		if (angle > 90) {
			angle = -1 * (angle - 180);
		}
		// this is... I'm too lazy to reverse engineer this out of the code, but it's known to
		// work
		angle *= -1;

		return angle;
	}



}
